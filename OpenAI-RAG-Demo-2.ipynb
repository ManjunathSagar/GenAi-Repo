{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0688e17f-a374-4be4-b80d-1ff02c60ea90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "695fcaa4-9b51-4cff-a628-e12700a5a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"OPENAI_API_\"]=\"Put your OpenAI API Keys here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5ed6d3c-1db7-4f31-897b-3eec6d7f3424",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.theverge.com/2024/4/18/24133808/meta-ai-assistant-llama-3-chatgpt-openai-rival\"\n",
    "loader = WebBaseLoader(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35343e9b-e0e3-4c0a-83aa-c0ee2a5216b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88ca6072-237e-41f1-89d7-30e1bf9d86bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 200, chunk_overlap = 50)\n",
    "chunks = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "938f2164-0cae-44a8-850e-1207a7465e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a931d808-b417-4280-8b2c-3644ed7b3929",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95a5d2ab-47d6-44ce-a29a-d8aba8acd751",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5ec9094-485c-43bb-9a5f-fddcd7083ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53700014-6152-45e9-b6bb-fc4c6993913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f65c11f3-bfe0-4a9f-b1f7-02ef29269757",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"SYSTEM: You are a question answer bot. \n",
    "                 Be factual in your response.\n",
    "                 Respond to the following question: {question} only from \n",
    "                 the below context :{context}. \n",
    "                 If you don't know the answer, just say that you don't know.\n",
    "               \"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91375007-0903-4bf4-b2c6-445c43e89bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c9faa48-8a72-4814-8991-c66512057976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The largest Llama 3 model will have over 400 billion parameters.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What's the size of the largest Llama 3 model?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f6e884-b4b5-41e1-8f13-2a95c3bd8154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
